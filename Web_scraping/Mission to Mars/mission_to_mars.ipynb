{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'C:/Users/wabug/Desktop/Drivers/chromedriver_win32/chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web page url to be scrapped from\n",
    "url=\"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beautiful soup \n",
    "html=browser.html\n",
    "soup=BeautifulSoup(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News Title: Mars Scientists Investigate Ancient Life in Australia\n",
      "Paragraph:Teams with NASA's Mars 2020 and ESA's ExoMars practiced hunting for fossilized microbial life in the Australian Outback in preparation for their Red Planet missions. \n"
     ]
    }
   ],
   "source": [
    "#finding news title\n",
    "title=soup.find(\"div\",class_=\"content_title\").text\n",
    "print(f\"News Title: {title}\")\n",
    "#finding paragraph\n",
    "paragraph=soup.find(\"div\", class_=\"article_teaser_body\").get_text()\n",
    "print(f\"Paragraph:{paragraph}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images of jpl\n",
    "images_url=\"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(images_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_html=browser.html\n",
    "soup=BeautifulSoup(image_html,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space Image URL : https://www.jpl.nasa.gov/spaceimages/images/wallpaper/PIA23511-640x350.jpg\n"
     ]
    }
   ],
   "source": [
    "#getting the featured image url\n",
    "image = soup.find('img', class_ = 'thumb')['src']\n",
    "featured_image_url = \"https://www.jpl.nasa.gov\" + image\n",
    "print(f\"Space Image URL : {featured_image_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding mars weather\n",
    "weather_url=\"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(weather_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BeautifulSoup object; parse with 'html.parser'\n",
    "weather_html = browser.html\n",
    "weather_soup = BeautifulSoup(weather_html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save the tweet text for the weather report as a variable called\n",
    "tweet =weather_soup.find(\"div\", \n",
    "                                       attrs={\n",
    "                                           \"class\": \"tweet\", \n",
    "                                            \"data-name\": \"Mars Weather\"\n",
    "                                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_weather = tweet.find(\"p\", \"tweet-text\").get_text()\n",
    "print(f\"Mars Weather Tweet:{mars_weather}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mars_df = pd.read_html(\"https://space-facts.com/mars/\")[0]\n",
    "mars_df.columns=[\"Description\", \"Value\"]\n",
    "mars_df.set_index(\"Description\", inplace=True)\n",
    "mars_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the USGS Astrogeology site \n",
    "url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hemisphere_image_urls = []\n",
    "\n",
    "# Get a List of All hemispheres\n",
    "links = browser.find_by_css(\"a.product-item h3\")\n",
    "for item in range(len(links)):\n",
    "    hemisphere = {}\n",
    "    \n",
    "#Find Element on Each Loop to Avoid a Stale Element Exception\n",
    "    browser.find_by_css(\"a.product-item h3\")[item].click()\n",
    "    \n",
    "# Get Hemisphere Title\n",
    "    hemisphere[\"title\"] = browser.find_by_css(\"h2.title\").text\n",
    "    \n",
    "# Find Sample Image Anchor Tag & Extract <href>\n",
    "    sample_element = browser.find_link_by_text(\"Sample\").first\n",
    "    hemisphere[\"img_url\"] = sample_element[\"href\"]\n",
    "    \n",
    "# Append Hemisphere Object to List\n",
    "    hemisphere_image_urls.append(hemisphere)\n",
    "    \n",
    "# Navigate Backwards\n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hemisphere_image_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d78b33a1c71c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhemisphere_image_urls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'hemisphere_image_urls' is not defined"
     ]
    }
   ],
   "source": [
    "hemisphere_image_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
